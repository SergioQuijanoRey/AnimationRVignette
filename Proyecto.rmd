---
title: "Animaciones en R con el paquete animation"
author:
    - "Lucía Salamanca López"
    - "Sergio Quijano Rey"
    - "Alejandro Borrego Megías"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Animaciones en R con el apquete animation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

<!-- Este codigo es necesario para inicializar el documento tipo Vignette -->
```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Animaciones en R

Durante el curso hemos explorado las posibilidades de R en el ámbito de la Estadística computacional, haciendo análisis exploratorio de datos, problemas de regresión lineal, aproximación de integrales y distribuciones, etc... Además hemos explorado diversas funciones que permiten generar gráficos que ayudan a explicar y entender mejor estos procedimientos.

Motivados por la gran potencia de R para la generación de gráficos decidimos explorar si también existen paquetes que permitan crear animaciones para comprender mejor algoritmos clásicos tanto de estadística como de la matemática aplicada en general. Es por ello que nuestro proyecto se basa en utilizar algunas de las funciones del paquete *animation* y valorar los resultados que se obtienen.

El paquete *animation* proporciona un extenso catálogo de funciones que abarcan problemas de la teoría de probabilidad, la estadística multivariante, modelos lineales, series temporales y algoritmos de minería de datos y aprendizaje automático. La finalidad del paquete mostrar el funcionamiento de estas herramientas visualmente con una finalidad didáctica ^[Todas las funcionaliadades del paquete se pueden consultar en su [Documentación oficial](https://cran.r-project.org/web/packages/animation/animation.pdf)].

Es importante mencionar que las animaciones no se pueden visualizar en este HTML, cada una de las funciones que usemos genera un HTML con un nombre de acuerdo a la función que permitirá ver la animación y controlar su ejecución permitiendo aumentar o disminuir la velocidad, o parar la animación en un instante determinado. Estos ficheros se entregan junto con el proyecto final.

# Nota previa

El paquete falla cuando en la instrucción `saveHTML` no indicamos tanto un nombre para las imágenes único como un directorio unico para guardar estas imágenes. Este no lo hemos encontrado documentado, así que lo mostramos en esta nota para evitar que el lector repita el mismo fallo, que es bastante complicado de *trackear*.

# Instalación del paquete *animation*

Para la instalación del paquete lo hacemos a través de **CRAN** como con el resto de paquetes que hemos empleado durante el curso.

```{r eval = FALSE}
install.packages("animation")
```

Una vez hecho esto, ya podemos cargar la librería en el proyecto.

```{r}
library(animation)
```

# Ejemplos

A continuación se muestran algunos ejemplos de uso de algunas de sus funciones, como se verá, en todos los casos hacemos uso de una función denominada `saveHTML()`, que nos permite convertir en un fichero HTML cada una de las animaciones, como parámetros debemos pasar la secuencia de imágenes que compoenen la animación y que son generadas por la función principal, y el nombre del fichero HTML que queremos generar.

## Método de Bisección

La siguiente función aplica el método de Bisección para encontrar una raíz de cierta función continua $f(x)$. Si recordamos el método, este requiere de dos puntos iniciales $a,b$ de manera que $f(a)>0$ y $f(b)<0$ o viceversa. De esta forma, por el teorema de Bolzano sabemos que en el intervalo $[a,b]$ hay una raíz de la función.

El algoritmo en cada iteración calcula el punto medio $c$ del intervalo $[a,b]$ y evalúa la función en ese punto medio, si el signo es igual que $f(a)$ reemplaza $a$ por $c$ y si no al contrario. De esta manera vamos reduciendo el intervalo en que se encuentra la raíz hasta que se obtenga la raíz exacta o bien se sobrepase una cierta tolerancia.

En nuestro caso vamos a probar con la función $f(x)=x^3 - 7x -10$ y vamos a usar el intervalo $[-3,5]$ pues como vemos en ese intervalo se cumplen las condiciones del algoritmo y hay una raíz.


```{r}
f = function(x) x^3 - 7 * x - 10
curve(f, from = -3, to=5)
abline(h=0)
```

A continuación usamos la función de `animation` correspondiente, se trata de `bisection.method` y requiere como parámetros la función $f$ que usaremos y los valores iniciales $a,b$ del método de bisección:

```{r, dev='png'}
saveHTML({bisection.method(f, c(-3, 5))
},htmlfile = "Biseccion.html", img.name = "biseccion", imgdir = "images/biseccion")
```

En el fichero [Biseccion.html](Biseccion.html) se puede encontrar la animación guardada.

## Método de Gradiente Descendente

Vamos a explorar la función que permite visualizar el método para encontrar mínimos locales de funciones en dos dimensiones (en este caso) conocido como Gradiente Descendente.

El método sigue la intuición de que el gradiente de una función apunta siempre a máximos locales, luego lo que hacemos es ir en la dirección contraria del gradiente para tratar de hallar mínimos locales. Este método no garantiza que el mínimo obtenido sea el mínimo global de la función (a no ser que la función sea convexa).

Para ello partimos de un punto inicial aleatorio del dominio de la función, y en cada iteración nos desplazamos en la dirección que apunta el gradiente cambiado de signo dando un paso de cierto tamaño que idealmente será grande para aproximarse rápido al mínimo y luego se reducirá para ajustar con precisión dicho mínimo.

La función que emplearemos será:

```{r, dev='png'}
f1 = function(x, y) x^2 + 3 * sin(y)
x <- seq(pi*-2,pi*2,length.out=100)
y <- seq(pi*-2,pi*2,length.out=100)
z <- outer(x^2,3* sin(y),`+`)
persp(x,y,z,theta = 30)
```

Como podemos apreciar en la imagen, la función tiene dos mínimos en el domino que usaremos que es $[-2\pi,2\pi] \times [-2\pi,2\pi]$.

Para esta tarea usaremos la función `grad.desc`. Los parámetros que debemos pasarle son: La función que vamos a usar, el dominio en el que trabajaremos y el punto inicial, que en nuestro caso será el $(-2\pi,2)$.

```{r, dev='png'}
saveHTML({grad.desc(f1, pi * c(-2, -2, 2, 2), c(-2 * pi, 2))
},htmlfile = "GD.html", img.name = "gradiente_descendiente", imgdir = "images/gradiente_descendiente")
```

En el fichero [GD.html](GD.html) se puede encontrar la animación guardada.

## Integración de Monte Carlo

El paquete `animation` incluye una función que realiza la animación del método de integración de Monte Carlo.

Este método utiliza números aleatorios para calcular el valor de integrales del estilo:

$$ I = \int \limits_0^1 h(x) dx$$
Para ello, teniendo en cuenta que la función de densidad de la distribución uniforme en el intervalo $(0,1)$ es $f(x)=1$, podemos escribir la integral anterior como:

$$ I = \int \limits_0^1 h(x) dx = \Bbb{E}[h(X)]$$

Donde $X \sim \mathcal{U}$. Al describirlo como una media teórica, podemos aproximarla simulando $n$ variables aleatorias uniformes $X_1,\dots,X_n$:

$$ I = \int \limits_0^1 h(x) dx = \Bbb{E}[h(X)] \approx \frac{1}{n}  \sum_{i=1}^{n}h(X_i)$$

Lo que muestra la función `MC.samplemean` son los rectángulos de ancho $\frac1n$ y de alto $h(x_i)$. De esta manera podemos comparar gráficamente la diferencia entre el valor exacto de la integral y la aproximación por el método de Monte Carlo.

Los argumentos de la función son: la función a integrar, el número de puntos que se toman de la distribución uniforme, el color de los rectángulos y si las posiciones de los rectángulos en el eje x deben ser ajustadas.

Esta función devuelve una lista con los números aleatorios generados, la función evaluada en dicho puntos, el valor de la n y el valor estimado de la integral.

Vamos a mostrar un ejemplo con la función $h(x) =4x^4$.

Primero mostramos un gráfico de la función:

```{r, fig.align='center',fig.cap='Función a integrar'}
# definimos la función a integrar
h<-function(x) (4*x^4) * (x>0 & x<1)
# visualizamos la función en el dominio de integración16
curve(h,0,1)
```

Ahora generamos y guardamos la animación:

```{r,dev='png', include = FALSE}
set.seed(1)
generate_result <- function() {
    return(
        MC.samplemean(FUN = h,adj.x = FALSE, col.rect = c(rgb(0, 0, 0, 0.3), rgb(1, 0, 0)), border = NA, n=60)
    )
}
saveHTML(generate_result(), htmlfile = "MonteCarlo.html", img.name = "montecarlo", imgdir = "images/montecarlo")
```

Guardo el resultado de la computación y mostramos ciertos valores numéricos:

```{r fig.show='hide'}
montecarlo <- generate_result()
```

```{r}
# Mostramos la estimación de la integral
montecarlo$est
```

Sabemos que el valor de la integral es $\frac{4}{5}$ por lo que el error relativo de la aproximación es de:

```{r}
abs(montecarlo$est-4/5)/(4/5)
```

Podemos encontrar la animación en el archivo [MonteCarlo.html](MonteCarlo.html).

## Moving block

El paquete `animation` incluye la función `moving.block` que permite mostrar un conjunto de datos como subconjuntos de éstos para así obtener una visión ampliada de los mismos. De otra manera, va mostrando los datos en pequeños subconjuntos para poder representarlos por partes y así ver los datos contiguos en un gráfico separado del resto, simulando un recorrido panorámico por la gráfica de todo el conjunto de datos.

Como parámetros se pasan los datos como un vector numérico o una matriz de dos columnas, el tamaño de cada bloque, es decir, el número de elementos que serán representados en cada paso y la función que sirve para representar los datos (ej: scatterplot, plot, curve, una función personalizada...).

\

Para mostrar un ejemplo vamos a hacer uso de `ObamaSpeech` que se encuentra dentro del paquete animation. Cada dato de este vector simboliza el número de palabras en cada parráfo del discurso de Obama tras ganar las elecciones presidenciales.

```{r,dev='png'}
saveHTML({moving.block(dat = ObamaSpeech, FUN = function(...,dat = dat, i = i, block = block) {plot(...,x = i + 1:block, xlab = "índice del párrafo", ylim = range(dat), ylab = sprintf("ObamaSpeech[%s:%s]", i + 1, i + block))}, type = "o", pch = 20)},htmlfile = "Obama.html", img.name = "Obama", imgdir = "images/obama")
```

Podemos ver la animación en el archivo [Obama.html](./Obama.html).

## Clasificación usando *k-NN*

*k-NN* o *k-Vecinos más cercanos* es un algoritmo de clasificación supervisado, no paramétrico. El procedimiento de este algoritmo es muy sencillo:

1. Guardamos una serie de datos que servirán para clasificar futuras entradas
   - Notar que no hay proceso de aprendizaje, solamente almacenamos los ejemplos de entrenamiento
2. Cuando llega un ejemplo a clasificar:
    - Miramos la clase de las $k$ clases más cercanas al ejemplo
    - Elegimos la clase del nuevo ejemplo, normalmente por voto mayoritario (para ello, lo ideal es que $k$ sea un número impar)
    - Con el valor de $k$ controlamos la regularización que queremos introducir en el modelo. Un valor más alto de $k$ implica una regularización mayor

Para mostrar esto con un ejemplo, trabajamos con un dataset que queremos segmentar en distintos clusters. En concreto, trabajaremos con el conocido *Iris Dataset*. Nuestro objetivo es clasificar los datos en tres tipos de flores: *setosa*, *versicolor* y *virginica*. Para ello, escogeremos dos características de las cuatro disponibles:

1. Sepal.Length
2. Sepal.Width
3. Petal.Length
4. Petal.Width

Nos quedamos con las dos primeras variables.

```{r}
# El dataset iris esta pre-cargado en R
data <- iris
head(data)

# Nos quedamos solo con dos columnas, porque la animacion solo soporta dos
# dimensiones
data <- data[, c("Sepal.Length", "Sepal.Width")]
head(data)
```

Además, la función del paquete exige que nos quedemos con dos *datasets*, uno de entrenamiento y otro de test, así que a continuación realizamos la separación ^[He usado el siguiente código de [StackOverflow](https://stackoverflow.com/a/17200430), que he adaptado para realizar la separación]:

```{r}
# 70% para el entrenamiento, 30% para test
train_size <- floor(0.75 * nrow(data))

# Localizamos los indices para el entrenamiento
train_ind <- sample(seq_len(nrow(data)), size = train_size)

# Realizamos la separacion
data_train <- data[train_ind, ]
data_test <- data[-train_ind, ]
```

También necesito las clases de los ejemplos de entrenamiento por separado, así que las tomamos a continuación. Notar que no las podíamos tomar antes, porque hemos permutado las filas del dataset para realizar la división en entrenamiento y test.

```{r}
training_classes <- iris[train_ind, ]$Species
head(training_classes, 10)
```

Con esto, ya podemos aplicar el algoritmo que visualizaremos:

```{r}
# Nos fijaremos en los cinco vecinos más cercanos
k <- 5


# Establecemos la velocidad de la animacion
ani.options(interval = 1)

# Coloco la ejecucion del algoritmo en una funcion para tener un codigo limpio
# (no poner esto en `saveHTML`) y para que no se muestre en el documento html
# principal, sin animar
generate_result <- function() {
    return(knn.ani(
        train = data_train,
        test = data_test,
        k = k,
        cl = iris[train_ind, ]$Species
    ))
}

# Aplicamos el algoritmo, salvandolo en un fichero html para visualizarse
saveHTML(
    generate_result(),
    htmlfile = "kNN.html",
    img.name = "k_nn",
    imgdir = "images/knn"
)
```

El resultado lo podemos visualizar en [este documento html](kNN.html)

## Clusterización usando K-means

*K-means* es un algoritmo de clusterización. El objetivo del algoritmo es dividir $n$ ejemplos en $k$ clusters. El algoritmo minimiza la media de las distancias euclídeas de los ejemplos en cada cluster. El proceso del algoritmo es el siguiente:

1. Se generan $k$ centroides aleatorios
2. Se clasifican todos los ejemplos usando los $k$ centroides
3. Una vez que tenemos todos los ejemplos clasificados, se calculan los nuevos centroides usando los ejemplos de cada cluster
4. Si los centroides no han cambiado, hemos terminado. En otro caso, volvemos al paso 2

Por tanto, estamos hablando de un algoritmo de aprendizaje no supervisado, puesto que en ningún momento estamos usando la información de la clase a la que pertenece cada ejemplo.

Cuando llega un nuevo ejemplo a clasificar, lo que hacemos es asignar el cluster cuyo centroide esté más cercano. Esto es ventajoso porque a la hora de realizar inferencias con el modelo, solo tenemos que almacenar los centroides (que actúan como prototipos del cluster) y no todos los ejemplos de entrenamiento, como hemos comentado que pasaba en *k-NN*.

Volvemos a trabajar con el mismo *dataset*, quedándonos con las mismas variables:

```{r}
# El dataset iris esta pre-cargado en R
data <- iris
head(data)

# Nos quedamos solo con dos columnas, porque la animacion solo soporta dos
# dimensiones
data <- data[, c("Sepal.Length", "Sepal.Width")]
head(data)
```

Aunque el algoritmo sea un algoritmo de aprendizaje no supervisado, sabemos que tenemos 3 tipos de flores, así que establecemos a 3 el número de centros:

```{r}
num_centers <- 3
```

Con esto, ya podemos aplicar el algoritmo que visualizaremos:

```{r}

# Establecemos la velocidad de la animacion
ani.options(interval = 1)

# Coloco la ejecucion del algoritmo en una funcion para tener un codigo limpio
# (no poner esto en `saveHTML`) y para que no se muestre en el documento html
# principal, sin animar
generate_result <- function() {
    return(kmeans.ani(
        x = data,
        centers <- num_centers,
    ))
}

# Aplicamos el algoritmo, salvandolo en un fichero html para visualizarse
saveHTML(
    generate_result(),
    htmlfile = "kMeans.html",
    img.name = "k_means",
    imgdir = "images/kmeans"
)
```

El resultado lo podemos visualizar en [este documento html](kMeans.html)
